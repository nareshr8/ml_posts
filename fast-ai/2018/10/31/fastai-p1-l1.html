<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Understanding of Fast AI - Course V3 (Part 1 - Lesson 1) | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Understanding of Fast AI - Course V3 (Part 1 - Lesson 1)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes for Image Classification" />
<meta property="og:description" content="Notes for Image Classification" />
<link rel="canonical" href="https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html" />
<meta property="og:url" content="https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-31T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2018-10-31T00:00:00-05:00","headline":"Understanding of Fast AI - Course V3 (Part 1 - Lesson 1)","description":"Notes for Image Classification","mainEntityOfPage":{"@type":"WebPage","@id":"https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html"},"@type":"BlogPosting","url":"https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html","dateModified":"2018-10-31T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml_posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nareshr8.github.io/ml_posts/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/ml_posts/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Understanding of Fast AI - Course V3 (Part 1 - Lesson 1) | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Understanding of Fast AI - Course V3 (Part 1 - Lesson 1)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes for Image Classification" />
<meta property="og:description" content="Notes for Image Classification" />
<link rel="canonical" href="https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html" />
<meta property="og:url" content="https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-31T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2018-10-31T00:00:00-05:00","headline":"Understanding of Fast AI - Course V3 (Part 1 - Lesson 1)","description":"Notes for Image Classification","mainEntityOfPage":{"@type":"WebPage","@id":"https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html"},"@type":"BlogPosting","url":"https://nareshr8.github.io/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html","dateModified":"2018-10-31T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://nareshr8.github.io/ml_posts/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml_posts/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml_posts/about/">About Me</a><a class="page-link" href="/ml_posts/search/">Search</a><a class="page-link" href="/ml_posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Understanding of Fast AI - Course V3 (Part 1 - Lesson 1)</h1><p class="page-description">Notes for Image Classification</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2018-10-31T00:00:00-05:00" itemprop="datePublished">
        Oct 31, 2018
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ml_posts/categories/#fast-ai">fast-ai</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#whats-your-pet">What’s your pet</a>
<ul>
<li class="toc-entry toc-h2"><a href="#looking-at-the-data">Looking at the data</a></li>
<li class="toc-entry toc-h2"><a href="#training-resnet34">Training: resnet34</a></li>
<li class="toc-entry toc-h2"><a href="#results">Results</a></li>
<li class="toc-entry toc-h2"><a href="#unfreezing-fine-tuning-and-learning-rates">Unfreezing, fine-tuning, and learning rates</a></li>
<li class="toc-entry toc-h2"><a href="#training-resnet50">Training: resnet50</a></li>
<li class="toc-entry toc-h2"><a href="#other-data-formats">Other data formats</a></li>
</ul>
</li>
</ul><p>This is the notes of first lesson of the list of lessons in the Part 1 of  Fast AI V3 course. Though I went though few lessons on Fast AI course of last year, I was sure to do this course. This is the first course that comes after the first version release of Fast AI library itself. Last year it was in Beta Version (think 0.7 when I took it online) and it is now into version 1.0.14.</p>

<h1 id="whats-your-pet">
<a class="anchor" href="#whats-your-pet" aria-hidden="true"><span class="octicon octicon-link"></span></a>What’s your pet</h1>

<p>In this lesson we will build our first image classifier from scratch, and see if we can achieve world-class results. Let’s dive in!</p>

<p>The lines in jupyter notebook that starts with ‘%’ are called <strong><a href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">Line Magics</a></strong>. These are not instructions for Python to execute, but to Jupyter notebook.</p>

<p>They ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.</p>

<p>The <code class="highlighter-rouge">reload_ext autoreload</code> reloads modules automatically before entering the execution of code typed at the IPython prompt.</p>

<p>The next line <code class="highlighter-rouge">autoreload 2</code> imports all modules before executing the typed code.</p>

<p>The documentation on autoreload is available <a href="https://ipython.org/ipython-doc/3/config/extensions/autoreload.html">here</a></p>

<p>The next line is to plot the graphs inside the jupyter notebook. We use <code class="highlighter-rouge">matplotlib inline</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">reload_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<p>We import all the necessary packages. We are going to work with the <a href="http://www.fast.ai/2018/10/02/fastai-ai/">fastai V1 library</a> which sits on top of <a href="https://hackernoon.com/pytorch-1-0-468332ba5163">Pytorch 1.0</a>. The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.vision</span> <span class="kn">import</span> <span class="o">*</span>
</code></pre></div></div>

<h2 id="looking-at-the-data">
<a class="anchor" href="#looking-at-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Looking at the data</h2>

<p>We are going to use the <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIIT Pet Dataset</a> by <a href="http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf">O. M. Parkhi et al., 2012</a> which features 12 cat breeds and 25 dogs breeds. Our model will need to learn to differentiate between these 37 distinct categories. According to their paper, the best accuracy they could get in 2012 was 59.21%, using a complex model that was specific to pet detection, with separate “Image”, “Head”, and “Body” models for the pet photos. Let’s see how accurate we can be using deep learning!</p>

<p>We are going to use the <code class="highlighter-rouge">untar_data</code> function to which we must pass a URL as an argument and which will download and extract the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">help</span><span class="p">(</span><span class="n">untar_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Help on function untar_data in module fastai.datasets:

untar_data(url: str, fname: Union[pathlib.Path, str] = None, dest: Union[pathlib.Path, str] = None, data=True)
    Download `url` if doesn't exist to `fname` and un-tgz to folder `dest`
</code></pre></div></div>

<p>The <code class="highlighter-rouge">untar_data</code> is  great idea for downloading the URL provided and download and untar.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">PETS</span><span class="p">);</span> <span class="n">path</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet')
</code></pre></div></div>

<p>In Python, we can extend and add new functionalities to the existing python modules. I found <a href="https://stackoverflow.com/a/2982/1367953">this</a> link useful for creating one.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images'),
 PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/annotations')]
</code></pre></div></div>

<p>The pathlib thats part of Python 3 has the notation <code class="highlighter-rouge">/</code> which is useful to navigate into the directory as in the actual directory. We use to create <em>Path</em> variables with the new location.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path_anno</span> <span class="o">=</span> <span class="n">path</span><span class="o">/</span><span class="s">'annotations'</span>
<span class="n">path_img</span> <span class="o">=</span> <span class="n">path</span><span class="o">/</span><span class="s">'images'</span>
</code></pre></div></div>

<p>Lets check all the images in the image directory</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fnames</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_img</span><span class="p">)</span>
<span class="n">fnames</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images/leonberger_34.jpg'),
 PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images/pug_203.jpg'),
 PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images/Siamese_203.jpg'),
 PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images/scottish_terrier_98.jpg'),
 PosixPath('/home/nbuser/courses/fast-ai/course-v3/nbs/data/oxford-iiit-pet/images/beagle_76.jpg')]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pat</span> <span class="o">=</span> <span class="s">r'/([^/]+)_\d+.jpg$'</span>
</code></pre></div></div>

<p>The first thing we do when we approach a problem is to take a look at the data. We <em>always</em> need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like.</p>

<p>The main difference between the handling of image classification datasets is the way labels are stored. In this particular dataset, labels are stored in the filenames themselves. We will need to extract them to be able to classify the images into the correct categories. Fortunately, the fastai library has a handy function made exactly for this, <code class="highlighter-rouge">ImageDataBunch.from_name_re</code> gets the labels from the filenames using a <a href="https://docs.python.org/3.6/library/re.html">regular expression</a>. A detailed explaination found on an interesting read about the same lines of code in this tutorial is <a href="https://medium.com/@youknowjamest/parsing-file-names-using-regular-expressions-3e85d64deb69">here</a>.</p>

<p><strong>Loading Images:</strong></p>

<p><code class="highlighter-rouge">ImageDataBunch</code> is used to do classification based on images. We use the method <code class="highlighter-rouge">from_name_re</code> to represent that the name of the classification is to be got from the name of the file using a regular expression. It takes the following parameters:</p>
<ul>
  <li>
<code class="highlighter-rouge">path_img</code> the path of the images directory</li>
  <li>
<code class="highlighter-rouge">fnames</code> the list of files in that directory</li>
  <li>
<code class="highlighter-rouge">pat</code> the regex pattern that is used to extract <em>label</em> from the file name</li>
  <li>
<code class="highlighter-rouge">ds_tfms</code> the transformations that are needed for the image. This includes centering, cropping and zooming of the images.</li>
  <li>
<code class="highlighter-rouge">size</code> the size to which the image is to be resized. 
This is usually a square image. This is done because of the limitation in the GPU that the GPU performs faster only when it has to do similar computations (such as matrix multiplication, addition and so on) on all the images.</li>
</ul>

<p><strong>Data Normalisation:</strong></p>

<p>This is done to ensure that the images are easy to do mathematical calculations that we are looking for after that. This includes changing the range of values of RGB from <em>0-255</em> to <em>-1 to 1</em>.This is because we have 3 color channels namely Red, Green and Blue. For the pixel values we might have some color channels that varies slightly and some that doesn’t. So, we need to normalise the images with mean as 0 and standard deviation as 1.</p>

<p>One another thing to note is that we are using the residual network, which is pretrained. So, we must use the same normalisation that the residual network is using in order to use the best of the pretrained model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span><span class="n">path_img</span><span class="p">,</span> <span class="n">fnames</span><span class="p">,</span> <span class="n">pat</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;fastai.vision.data.ImageDataBunch at 0x7f21d8961eb8&gt;
</code></pre></div></div>

<p>Now, we can look into the image samples along with the classification name to check if everything that we have done thus far is doing great.</p>

<p>Its important to check this as we may understand some images might have some kind of issue over the other, like rotated in odd ways, just text on it, 2 different categories of classificatiers on it and so on.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">doc</span><span class="p">(</span><span class="n">ImageDataBunch</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_24_0.png" alt=""></p>

<p>We use the <code class="highlighter-rouge">data.classes</code> to indicate the total number of distinct labels that were found. In our case, since wwe have extracted the labels from the regular expression, it indicates the number of distinct labels that were extracted from the regular expression.</p>

<p><code class="highlighter-rouge">data.c</code> gives the total number of classifications that were found in the dataset</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">classes</span><span class="p">),</span><span class="n">data</span><span class="o">.</span><span class="n">c</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['leonberger', 'pug', 'Siamese', 'scottish_terrier', 'beagle', 'Birman', 'Abyssinian', 'great_pyrenees', 'chihuahua', 'havanese', 'japanese_chin', 'yorkshire_terrier', 'Persian', 'Ragdoll', 'pomeranian', 'newfoundland', 'Bombay', 'shiba_inu', 'german_shorthaired', 'Bengal', 'samoyed', 'boxer', 'wheaten_terrier', 'miniature_pinscher', 'english_cocker_spaniel', 'Maine_Coon', 'Sphynx', 'British_Shorthair', 'staffordshire_bull_terrier', 'keeshond', 'saint_bernard', 'american_pit_bull_terrier', 'Russian_Blue', 'american_bulldog', 'english_setter', 'Egyptian_Mau', 'basset_hound']





(37, 37)
</code></pre></div></div>

<h2 id="training-resnet34">
<a class="anchor" href="#training-resnet34" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training: resnet34</h2>

<p>Now we will start training our model. We will use a <a href="http://cs231n.github.io/convolutional-networks/">convolutional neural network</a> backbone and a fully connected head with a single hidden layer as a classifier. Since we are using Residual Network with 34 hidden units, all we have to do is to add a layer at the end on the residual network to transform the dimension of the residual network to the required output. In our case, it is 
to the 37 possible outputs.</p>

<p>We will train for 4 epochs (4 cycles through all our data).</p>

<p>We create a <code class="highlighter-rouge">learner</code> object that takes the data, network and the <code class="highlighter-rouge">metrics</code> . The <code class="highlighter-rouge">metrics</code> is just used to print out how the training is performing. We choose to print out the <code class="highlighter-rouge">error_rate</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span> <span class="o">=</span> <span class="n">create_cnn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /home/nbuser/.torch/models/resnet34-333f7ec4.pth
100%|██████████| 87306240/87306240 [00:02&lt;00:00, 29535503.58it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 03:19
epoch  train_loss  valid_loss  error_rate
1      1.156555    0.291909    0.091151    (00:53)
2      0.505356    0.249506    0.077179    (00:48)
3      0.312138    0.212065    0.074518    (00:49)
4      0.240234    0.198288    0.069195    (00:48)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'stage-1'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="results">
<a class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>

<p>Let’s see what results we have got.</p>

<p>We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly.</p>

<p>Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">11</span><span class="p">))</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_36_0.png" alt="png"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">doc</span><span class="p">(</span><span class="n">interp</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_38_0.png" alt="png"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('Ragdoll', 'Birman', 6),
 ('staffordshire_bull_terrier', 'american_pit_bull_terrier', 5),
 ('american_pit_bull_terrier', 'staffordshire_bull_terrier', 5),
 ('Egyptian_Mau', 'Bengal', 5),
 ('Birman', 'Ragdoll', 4),
 ('British_Shorthair', 'Russian_Blue', 4),
 ('Bengal', 'Egyptian_Mau', 3),
 ('english_cocker_spaniel', 'english_setter', 3),
 ('Maine_Coon', 'Ragdoll', 3),
 ('american_pit_bull_terrier', 'american_bulldog', 3),
 ('american_bulldog', 'staffordshire_bull_terrier', 3)]
</code></pre></div></div>

<h2 id="unfreezing-fine-tuning-and-learning-rates">
<a class="anchor" href="#unfreezing-fine-tuning-and-learning-rates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unfreezing, fine-tuning, and learning rates</h2>

<p>Since our model is working as we expect it to, we will <em>unfreeze</em> our model and train some more.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 01:07
epoch  train_loss  valid_loss  error_rate
1      1.070711    0.524961    0.168995    (01:07)
</code></pre></div></div>

<p>Since the Model underperformed while training after <em>unfreeze</em>, we would like to move to our previous best model that we have saved <strong>stage-1</strong>. We will finetune to improve from here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'stage-1'</span><span class="p">)</span>
</code></pre></div></div>

<p>We use the <code class="highlighter-rouge">lr_find</code> method to find the optimum learning rate. <strong>Learning Rate</strong> is an important hyper-parameter to look for. We traditionally use $\alpha$ to denote this parameter. If the Learning rate is too slow, we take more time to reach the most accurate result. If it is too high, we might not even end up reaching the accurate result. <a href="https://arxiv.org/abs/1506.01186">Learning Rate Finder</a> was idea of automatically getting the magic number (which is near perfect), to get this optimum learning rate. This was introducted in last year’s Fast AI course and continues to be useful.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LR Finder complete, type {learner_name}.recorder.plot() to see the graph.
</code></pre></div></div>

<p>After we run the finder, we plot the graph between loss and learning rate. We see a graph and typically choose a higher learning rate for which the loss is minimal. The higher learning rate makes sure that the machine ends up learning faster.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_49_0.png" alt="png"></p>

<p>We see around $1e^{-4}$ mark, we have a optimum learning rate. Now that we know the optimum learning rate.</p>

<p>Considering the fact that we are using a pretrained model of <em>resnet-34</em>, we know for sure that our previous layers of this neural network would learn to detect the edges and the later layers would learn complicated shapes such as the dogs and cats itself. We don’t want to ruin out the earlier layers which presumably does a good job of detecting the edges. But would like to improve the model in narrowing down classifying the image of dogs and cats to our needs, which is done in the later layers.</p>

<p>So, we will set a lower learning rate for earlier layers and higher one for the last layers.</p>

<p>The <em>slice</em> is used to provide the learning rate wherein, we just provide the range of learning rates (its min and max). The learning rate is set gradually higher as we move from the earlier layer to the latest layers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 02:14
epoch  train_loss  valid_loss  error_rate
1      0.199850    0.185868    0.064538    (01:07)
2      0.194062    0.182656    0.065203    (01:07)
</code></pre></div></div>

<p>That’s a pretty accurate model!</p>

<h2 id="training-resnet50">
<a class="anchor" href="#training-resnet50" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training: resnet50</h2>

<p>Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. Later in the course you can learn the details in the <a href="https://arxiv.org/pdf/1512.03385.pdf">resnet paper</a>).</p>

<p>Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let’s see if we can achieve a higher performance here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span><span class="n">path_img</span><span class="p">,</span> <span class="n">fnames</span><span class="p">,</span> <span class="n">pat</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="mi">299</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">48</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;fastai.vision.data.ImageDataBunch at 0x7f21d89b3860&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span> <span class="o">=</span> <span class="n">create_cnn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 16:40
epoch  train_loss  valid_loss  error_rate
1      0.646226    0.257891    0.085036    (03:53)
2      0.348598    0.244830    0.082399    (03:11)
3      0.236005    0.192446    0.061964    (03:11)
4      0.149788    0.147233    0.044825    (03:11)
5      0.100550    0.138161    0.048121    (03:11)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'stage-1-50'</span><span class="p">)</span>
</code></pre></div></div>

<p>It’s astonishing that it’s possible to recognize pet breeds so accurately! Let’s see if full fine-tuning helps:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 04:27
epoch  train_loss  valid_loss  error_rate
1      0.088951    0.151667    0.050758    (04:27)
</code></pre></div></div>

<p>In this case it doesn’t, so let’s go back to our previous model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'stage-1-50'</span><span class="p">)</span>
</code></pre></div></div>

<p>We now load the previous best model and would like to improve upon that model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">interp</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('american_pit_bull_terrier', 'staffordshire_bull_terrier', 6),
 ('Ragdoll', 'Birman', 5),
 ('Egyptian_Mau', 'Bengal', 5),
 ('Ragdoll', 'Persian', 4),
 ('staffordshire_bull_terrier', 'american_bulldog', 4),
 ('Maine_Coon', 'Ragdoll', 3)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LR Finder complete, type {learner_name}.recorder.plot() to see the graph.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_67_0.png" alt="png"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">3e-4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total time: 08:26
epoch  train_loss  valid_loss  error_rate
1      0.116429    0.138112    0.049440    (04:17)
2      0.084291    0.129927    0.044166    (04:08)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'stage-2-50'</span><span class="p">)</span>
</code></pre></div></div>

<p>Save the model as it seems a little more accurate</p>

<h2 id="other-data-formats">
<a class="anchor" href="#other-data-formats" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other data formats</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">);</span> <span class="n">path</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PosixPath('/home/jhoward/.fastai/data/mnist_sample')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tfms</span> <span class="o">=</span> <span class="n">get_transforms</span><span class="p">(</span><span class="n">do_flip</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_74_0.png" alt="png"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learn</span> <span class="o">=</span> <span class="n">ConvLearner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>VBox(children=(HBox(children=(IntProgress(value=0, max=2), HTML(value='0.00% [0/2 00:00&lt;00:00]'))), HTML(value…


Total time: 00:11
epoch  train loss  valid loss  accuracy
1      0.108823    0.025363    0.991168  (00:05)
2      0.061547    0.020443    0.994112  (00:05)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s">'labels.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>train/3/7463.png</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>train/3/21102.png</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>train/3/31559.png</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>train/3/46882.png</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>train/3/26209.png</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">data</span><span class="o">.</span><span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 1]
</code></pre></div></div>

<p><img src="..%5Cimg%5Cposts%5C2018-10-31-fastai-p1-l1%5Coutput_78_1.png" alt="png"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 1]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fn_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">path</span><span class="o">/</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s">'name'</span><span class="p">]];</span> <span class="n">fn_paths</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/jhoward/.fastai/data/mnist_sample/train/3/7463.png'),
 PosixPath('/home/jhoward/.fastai/data/mnist_sample/train/3/21102.png')]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pat</span> <span class="o">=</span> <span class="s">r"/(\d)/\d+\.png$"</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">fn_paths</span><span class="p">,</span> <span class="n">pat</span><span class="o">=</span><span class="n">pat</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['3', '7']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_func</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">fn_paths</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span>
        <span class="n">label_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">'3'</span> <span class="k">if</span> <span class="s">'/3/'</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="s">'7'</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['3', '7']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labels</span> <span class="o">=</span> <span class="p">[(</span><span class="s">'3'</span> <span class="k">if</span> <span class="s">'/3/'</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="s">'7'</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">fn_paths</span><span class="p">]</span>
<span class="n">labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['3', '3', '3', '3', '3']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_lists</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">fn_paths</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['3', '7']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

  </div><a class="u-url" href="/ml_posts/fast-ai/2018/10/31/fastai-p1-l1.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml_posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml_posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml_posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/nareshr8" title="nareshr8"><svg class="svg-icon grey"><use xlink:href="/ml_posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/nareshr8" title="nareshr8"><svg class="svg-icon grey"><use xlink:href="/ml_posts/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
